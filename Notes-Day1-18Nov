Go to the lab Master machine:

STEP 1: On Master Node Only:
=========================================
Execute below commands to Configure Docker Daemon:

sudo su -
sudo wget https://raw.githubusercontent.com/lerndevops/labs/master/kubernetes/0-install/daemon.json -P /etc/docker
sudo systemctl restart docker.service


Initialize kubernetes Master Node
======================================
# sudo kubeadm init

To fix the problem of The connection to the server localhost:8080 was refused - did you specify the right host or port?

Run the below commands

sudo mkdir -p $HOME/.kube 
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config 
sudo chown $(id -u):$(id -g) $HOME/.kube/config

install networking driver -- Weave/flannel/canal/calico etc... 

# kubectl apply -f https://raw.githubusercontent.com/projectcalico/calico/v3.24.1/manifests/calico.yaml

 Validate the setup by executing below commands 

# kubectl get nodes
=======================================
Step 2: ON ALL Worker Nodes

Configure Docker Daemon: 


# sudo wget https://raw.githubusercontent.com/lerndevops/labs/master/kubernetes/0-install/daemon.json -P /etc/docker
# sudo systemctl restart docker.service


=======================================
Step 3: Run Below on Master Node to get join token

# sudo kubeadm token create --print-join-command
Now copy the kubeadm join token from master & run it on all worker nodes

Example tooken looks like this:
# sudo kubeadm join 10.128.15.231:6443 --token mks3y2.v03tyyru0gy12mbt
--discovery-token-ca-cert-hash sha256:3de23d42c7002be0893339fbe558ee75e14399e11f22e3f0b34351077b7c4b56

==========================================
Validate on master node 

# kubectl get nodes
# kubectl get nodes -o wide

================================================================================================================

If worker nodes are in Noteready status, you can reset them by executing below steps:

ON MASTER NODE:
===========================
# kubectl delete node <nodename>

# kubectl get nodes

ON WORKER NODE TO BE RESET
================================
On the same Worker node that we have to reset execute below command:

# kubeadm reset --force
# sudo rm -rf /etc/kubernetes/

generate the token again on the Master node, execute below command:
===================================================
# sudo kubeadm token create --print-join-command

Copy the token

On Worker Node:
Paste the token, the node will join the master node

On Master Node:
# kubectl get nodes

=========================================================================

If master node is in NOT Ready status: Execute below steps to reset Master node

On Master Node:
===============================================

# kubectl delete -f https://raw.githubusercontent.com/projectcalico/calico/v3.24.1/manifests/calico.yaml

# kubeadm reset --force

# rm -rf /var/lib/kubelet /etc/kubernetes /var/lib/etcd $HOME/.kube

# sudo kubeadm init

sudo mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

## install networking driver -- Weave/flannel/canal/calico etc... 

# kubectl apply -f https://raw.githubusercontent.com/projectcalico/calico/v3.24.1/manifests/calico.yaml

generate the token again on the Master node, execute below command:
===============================================
# sudo kubeadm token create --print-join-command

Copy the token

On Worker Node:
Paste the token, the node will join the master node

On Master Node:
# kubectl get nodes


==========================================================

Creation of a Pod with a single container

kubectl create -f https://raw.githubusercontent.com/Sonal0409/Vodafone-Kubernetes-Notes/main/Day1-Notes/pod.yml

kubectl get pods

kubectl get pods -o wide

kubectl describe pod nginx-pod

=====================================

Creation of a Pod wih multiple containers -> Multi Container Pod
kubectl create -f https://raw.githubusercontent.com/Sonal0409/Vodafone-Kubernetes-Notes/main/Day1-Notes/multi-containerPod.yml

kubectl get pods -o wide


ReplicaSet Demo
=====================================
kubectl create -f https://raw.githubusercontent.com/Sonal0409/Vodafone-Kubernetes-Notes/main/Day1-Notes/ReplicaSet.yml

kubectl get pods

kubectl get pods --show-labels

kubectl get pods -l type=webserver

kubectl get all

kubectl scale --replicas=5 replicaset myrs1

kubectl scale --replicas=2 replicaset myrs1

kubectl delete replicaset myrs1

=====================================

Delete all exisitng replicaSet

kubectl delete all --all

Create Replicas using ReplicaSet YAML file

kubectl create -f https://raw.githubusercontent.com/Sonal0409/Vodafone-Kubernetes-Notes/main/Day2-Notes/Service/ClusterIPDemo/ReplicaSet.yml

kubectl get pods

kubectl get pods --show-labels

Create ClusterIp service

kubectl create -f https://raw.githubusercontent.com/Sonal0409/Vodafone-Kubernetes-Notes/main/Day2-Notes/Service/ClusterIPDemo/Service-clusterIP.yml

Validate:
kubectl get svc

Note down the service details:

mysvc1 ClusterIP 10.102.177.192 80/TCP 6m2s


Validate if a new pod is able to communicate with ngix replicas using cluster IP

create a new ubuntu pod for testing:

kubectl create -f https://raw.githubusercontent.com/Sonal0409/Vodafone-Kubernetes-Notes/main/Day2-Notes/Service/ClusterIPDemo/UbuntuPod.yml

Check ubuntu pod is running:

kubectl get pods

Log into Ubuntu pod

kubectl exec -it ubuntupod -- bash

Execute command to install curl package

apt-get update && apt-get install curl -y

Send a request to cluster ip, it will forward the request to any of the pod with target port as 80 and label as type=webserver

curl 10.102.177.192:80
========================================

Delete all exisitng replicaSet
kubectl delete all --all

Create new replicaSet and Nodeport Service
kubectl create -f https://raw.githubusercontent.com/Sonal0409/Vodafone-Kubernetes-Notes/main/Day2-Notes/Service/NotePortDemo/NodeportService.yml

Validate:
kubectl get all

kubectl get svc

service/mysvc NodePort 10.105.31.132 80:32111/TCP

Copy the node port.

Access the pod application by using MASTER VM desktop and node port


Go to Matser VM, and click on Desktop

Click on activites --> search for firefox --> enter localhost:<portnumber>

:

You will see the request sent to your pod.

======================================================================
Role Based Access in Kubernetes: RBAC
=================================================

Authorization and Authentication in Kubernetes -> RBAC
===========================================

Create a new server,and we will install kubectl on the new server  
OR
Use the existing worker node

We will use this server to access the controller and execute our Kubernetes 


==================================

On the Master Node:

Create a namespace by using the following command:
...

kubectl create namespace dev

Create a directory role.
...

mkdir role 
cd role

Generating an RSA private key and certificate requests
To generate an RSA private key, run the following command:
...

sudo openssl genrsa -out user3.key 2048

Use the following command to generate certificate requests:
...

sudo openssl req -new -key user3.key -out user3.csr

Enter any details like:

• Organization Name: namespace

• Common Name: user3

Run the following command to link an identity to a private key using a digital signature.


sudo openssl x509 -req -in user3.csr -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out user3.crt -days 500



Authorization : On the master node only
===================
role - permission/action of what user can do on the cluster 

rolebinding : bind the permissions to a user 

Creating role
To create a role,

...

kubectl create -f https://raw.githubusercontent.com/Sonal0409/Container-Orchestration-using-Kubernetes/main/Day4-Notes/RBAC/role.yml

kubectl get roles -n role

Creating a rolebinding
Create rolebinding by using the following command:

kubectl create -f https://raw.githubusercontent.com/Sonal0409/Container-Orchestration-using-Kubernetes/main/Day4-Notes/RBAC/rolebinding.yml

kubectl get rolebinding -n role

Setting credentials to the user

Set credentials to user3.

kubectl config set-credentials dave --client-certificate=/root/dev/dave.crt --client-key=/root/dev/dave.key

Set context to user3.

kubectl config set-context dave-context --cluster=kubernetes --namespace=dev --user=dave

Run the following command to display current contexts:
kubectl config get-contexts

Below steps on WORKER node or New node:
========================================
Copying the config file to the client machine
Copy the config file from the master node in the home directory to the worker node.

cd ..

cat .kube/config

Paste the copied config file into the client machine in root directory iteself.

vim myconf

copy the master machines config file contents to this file

In the worker node
create a role directory

mkdir role

cd role

Copy the crt and key files from the master node to the worker node in the /role directory.

keep the filename same as on master node

vim user3.crt

vim user3.key

Locate the home directory.
cd ..

Run the following commands to verify roles we have generated:
kubectl get pods --kubeconfig=myconf

kubectl create deployment test --image=docker.io/httpd -n role --kubeconfig=myconf

kubectl get pods --kubeconfig=myconf

kubectl get deployment --kubeconfig=myconf

The worker node can create, update, remove, and list pods, services, and deployments after using the master config settings.

========================

Next Steps:

View Kubeconfig
kubectl config --kubeconfig=base-config view

Get current conext information:
kubectl config --kubeconfig=base-config get-contexts

Switch Conexts:
kubectl config --kubeconfig=base-config use-context dev-frontend

Deletion
kubectl config delete-context my-cluster-context

